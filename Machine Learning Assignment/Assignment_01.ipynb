{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6b8be49-3b69-4bb8-80e0-fa35ec3f3a3e",
   "metadata": {},
   "source": [
    "**1. What does one mean by the term \"machine learning\" ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32daf0e-5007-413e-93e2-ba366d780382",
   "metadata": {},
   "source": [
    "**Ans:** Machine learning Popularly known as ML is a branch of Artificial Intelligence (AI) that allows software applications to become more accurate at predicting outcomes without being explicitly programmed to do so. \n",
    "\n",
    "Machine learning algorithms use historical data as input to predict new output values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b85717-fe61-45fc-a993-36a544537085",
   "metadata": {},
   "source": [
    "**2. Can you think of 4 distinct types of issues where it shines ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9bff2c-a0d5-45a8-8151-08d2470b1a7d",
   "metadata": {},
   "source": [
    "**Ans:** The following are some of the issues where Machine Learning can be used:\n",
    "\n",
    "**Image Recognition:** Image recognition is one of the most common applications of machine learning. It is used to identify objects, persons, places, digital images, etc. The popular use case of image recognition and face detection is Automatic friend tagging suggestion.\n",
    "\n",
    "**Speech Recognition:** While using Google, we get an option of Search by voice, it comes under speech recognition, and it's a popular application of Machine Learning. Speech recognition is a process of converting voice instructions into text, and it is also known as Speech to text, or Computer based speech recognition At present, machine learning algorithms are widely used by various applications of speech recognition. Google assistant, Siri, Cortana, and Alexa are using speech recognition technology to follow the voice instructions.\n",
    "\n",
    "**Traffic prediction:** It predicts the traffic conditions such as whether traffic is cleared, slow-moving, or heavily congested with the help of two ways: Real Time location of the vehicle form Google Map app and sensors Average time has taken on past days at the same time.\n",
    "\n",
    "**Product recommendations:** Machine learning is widely used by various e-commerce and entertainment companies such as Amazon, Netflix, etc., for product recommendation to the user.\n",
    "\n",
    "Machine learning algorithms have had good results on problems such has spam detection in email, cancer diagnosis, fraudulent credit card transactions, and automatically driving vehicles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8a2169-45f5-4142-bb09-7ccab426e019",
   "metadata": {},
   "source": [
    "**3. What is a labeled training set, and how does it work ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cd0ea-46c4-40ad-8b28-772daed80612",
   "metadata": {},
   "source": [
    "**Ans:**  A labeled training set is a collection of data where one of the features of the data indicates the class the training example belongs to. \n",
    "\n",
    "A labeled training set is used in supervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e81211-32d5-4084-984f-ed034a5eb6d5",
   "metadata": {},
   "source": [
    "**4. What are the two most important tasks that are supervised ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c437dc-1cf7-4ed1-8ed7-6d8991a1564c",
   "metadata": {},
   "source": [
    "**Ans:** The two most common supervised learning tasks are **regression** and **classification**. In a regression problem we our prediciton is a scalar value. When we're trying to solve a classification problem, our output is either 1 or 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c5b002-49ad-4e69-8350-90a9037a2a02",
   "metadata": {},
   "source": [
    "**5. Can you think of four examples of unsupervised tasks ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751eb03d-32f9-442e-9bb0-2dd6afe4c75f",
   "metadata": {},
   "source": [
    "**Ans:** Four common Unsupervised Tasks included **Clustering, Visualization, Dimensionality Reduction, and Association Rule Learning**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd02896a-295e-45b9-a155-516b62bf813c",
   "metadata": {},
   "source": [
    "**6. State the machine learning model that would be best to make a robot walk through various unfamiliar terrains ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bf6bac-4e75-4c39-9f64-dd4f00a182c9",
   "metadata": {},
   "source": [
    "**Ans:** The best Machine Learning algorithm to allow a Robot to walk in unfamiliar terrains is Reinforced Learning, where the robot can learn from response of the terrain to optimize itself.\n",
    "\n",
    "Reinforcement learning is a system where an \"agent\" observes the environment, selects and performs actions, then recieves a reward or punishment based on the result of the action. Over time the agent learns by itself what is the most productive strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ac81b9-8752-46a1-94d8-053578c72fd3",
   "metadata": {},
   "source": [
    "**7. Which algorithm will you use to divide your customers into different groups?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68b4654-75c5-4603-8b52-8335f250c532",
   "metadata": {},
   "source": [
    "**Ans:** The Best Algorithm to Segment Customers into different groups is either **Supervised Learning** (if the groups have known labels) or **Unsupervised Learning** (if there are no group labels).\n",
    "\n",
    "I would use some sort of clustering algorithm that can find the decision boundaries in the groups automatically. This is an unsupervised approach. However, if I already knew the categories of my customers, then I would choose a supervised approach and go with a classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc0776b-5e44-410a-855f-4783c8776f66",
   "metadata": {},
   "source": [
    "**8. Will you consider the problem of spam detection to be a supervised or unsupervised learning problem?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46d79d1-9f4d-47b3-95c5-9edf8ef38d6a",
   "metadata": {},
   "source": [
    "**Ans:** Spam detection is a Supervised Machine Learning problem because the labels are known (spam or no spam).\n",
    "Humans have a general idea about what spam is and what it isn't. We can use this notion to create a labeled dataset for an algorithm to learn from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32d4e07-2080-48af-aebc-81224a665e99",
   "metadata": {},
   "source": [
    "**9. What is the concept of an online learning system?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d924064-80b7-4648-8d82-332ad9c308f0",
   "metadata": {},
   "source": [
    "**Ans:** An online learning system learns from new data on-the-fly. As a result, the system is trained incrementally either by using one example at a time or using a mini-batch approach. This keeps each learning step cheap and memory efficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fb52ca-9cf1-4e35-84e8-1dadec30adc6",
   "metadata": {},
   "source": [
    "**10. What is out-of-core learning, and how does it differ from core learning?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d2b28-c66c-4806-86ab-0c2fd71d9793",
   "metadata": {},
   "source": [
    "**Ans:** Out-of-core learning is used when a dataset is too large to fit into a computer's memory. The algorithm loads part of the data, runs a training step, then repeats the process until it has run on all the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63156dc-b059-4e4e-b02a-a5c854379918",
   "metadata": {},
   "source": [
    "**11. What kind of learning algorithm makes predictions using a similarity measure?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a81ec5-95b3-493f-9556-ab62fde02242",
   "metadata": {},
   "source": [
    "**Ans:** Ans: Learning algorithm that relies on a similarity measure to make predictions is **Instance Based Algorithm**.  In an instance-based learning system, the algorithm learns the examples by heart, then uses the similarity measure to generalize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b50df3b-3957-4db8-845f-87bcdb78b464",
   "metadata": {},
   "source": [
    "**12. What's the difference between a model parameter and a hyperparameter in a learning algorithm?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da07f609-7757-4336-87b2-3404c1600dea",
   "metadata": {},
   "source": [
    "**Ans:** A hyperparameter is a parameter of the learning algorithm, not the model. For example, in a simple linear regression problem our model is parameterized by **theta** which is a vector of weights. In order to find the best values for **theta** we have a cost function which is run repeatedly by the gradient descent algorithm. Gradient descent has a hyperparameter called **alpha** which is the learning rate of the algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdea9b84-b8b4-49b5-9374-df36e0bc64e8",
   "metadata": {},
   "source": [
    "**13. What are the criteria that model-based learning algorithms look for? What is the most popular method they use to achieve success? What method do they use to make predictions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181c294-a7c5-43db-bc68-c84df526b1a0",
   "metadata": {},
   "source": [
    "**Ans:** Model based learning algorithm search for the optimal value of parameters in a model that will give the best results for the new instances. We often use a cost function or similar to determine what the parameter value has to be in order to minimize the function. The model makes prediction by using the value of the new instance and the parameters in its function.\n",
    "\n",
    " The goal for a model-based algorithm is to be able to generalize to new examples. To do this, model based algorithms search for optimal values for the model's parameters, often called **theta**. This searching, or \"learning\", is what machine learning is all about. Model-based system learn by minimizing a **cost function** that measures how bad the system is at making predicitons on new data, plus a penalty for model complexity if the model is regularized. To make a prediction, a new instance's features are fed into a hypothesis function which uses the minimized theta found by repeatedly running the cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881acb1d-3309-40a6-9842-532e4e63bca0",
   "metadata": {},
   "source": [
    "**14. Can you name four of the most important Machine Learning challenges?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5185eb5a-81f2-4618-b06a-4c2c55750edf",
   "metadata": {},
   "source": [
    "**Ans:** Four main challenges in Machine Learning include the following:\n",
    "\n",
    "1. Overfitting the Data (using a model too complicated)\n",
    "2. Underfitting the data (using a simple model)\n",
    "3. Lacking in Data\n",
    "4. Non Representative Data.\n",
    "\n",
    "Other challenges :\n",
    "\n",
    "1. Not gathering enough data, or sampling noise. Sampling noise means we'll have non-representative data as a result of chance.\n",
    "\n",
    "2. Using a dataset that is not representative of the cases you want to generalize to. This is called sampling bias. For example, if you want to train an algorithm with \"cat videos\", and all your videos are from YouTube, you're actually training an algorithm to learn about \"YouTube cat videos.\"\n",
    "\n",
    "3. Your dataset is full of missing values, outliers, and noise (poor measurments).\n",
    "\n",
    "4. The features in your dataset are irrelevant. Garbage in, garbage out.\n",
    "\n",
    "    a. Feature selection - choose the most relevant features from your dataset\n",
    "\n",
    "    b. Feature extraction - combine features in your dataset to generate a new, more useful feature\n",
    "\n",
    "5. When your model performs well on the training data, but not on test data, you've over fit your model. Models that suffer from overfitting do not generalize well to new examples. Overfitting happens when the model is too complex relative to the amount and noisiness of the data.\n",
    "    a. Try simplyfying the model by reducing the number of features in the data or constraining the parameters by reducing the degrees of freedom.\n",
    "\n",
    "    b. Gather more training data.\n",
    "\n",
    "    c. Reduce noise in the training data by fixing errors and removing outliers.\n",
    "\n",
    "6. When your model is too simple to learn the underlying structure of the data you've underfit your model.\n",
    "    a. Select a more powerful model with more parameters\n",
    "\n",
    "    b. Use feature engineering to feed better features to the model\n",
    "\n",
    "    c. Reduce the constraints of the model (increase degrees of freedom, reduce regularization parameter, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd189e70-f4b1-4194-bbd2-848f0d3fb926",
   "metadata": {},
   "source": [
    "**15. What happens if the model performs well on the training data but fails to generalize the results to new situations? Can you think of three different options?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e7dd8c-23ec-47de-9acf-2f741cf77861",
   "metadata": {},
   "source": [
    "**Ans:** If the model performs poorly to new instances, then it has overfitted on the training data. To solve this, we can do any of the following three:\n",
    "\n",
    "- Get more data\n",
    "- Implement a simpler model\n",
    "- Eliminate outliers or noise from the existing data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b3a955-8eb6-4ba3-8415-4f4659dd4c87",
   "metadata": {},
   "source": [
    "**16. What exactly is a test set, and why would you need one?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92c12d3-4e32-493a-89dc-1fbe253582a4",
   "metadata": {},
   "source": [
    "**Ans:** Test set is a set to test your model (fit using training data) to see how it performs.Test set is necessary to determine how good (or bad) a model performs.\n",
    "\n",
    "When we want to know how well our model generalizes to new cases we prefer to use a test set instead of actually deploying the system. To build the test set we split the training data (50-50, 60-40, 80-20 are common splits) into a training set and test set. Our model is training with the training set. Then we use the model to run predictions on the test set. Our error rate on the test set is called the generalization error or out-of-sample error. This error tells us how well our model performs on examples it has never seen before.\n",
    "\n",
    "If the training error is low, but the generalization error is high, it means we're overfitting our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4ba2c-05b0-4bc5-8225-83660d9b78da",
   "metadata": {},
   "source": [
    "**17. What is a validation set's purpose?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db793b0e-1a01-4b78-8fac-c7eb44583ed3",
   "metadata": {},
   "source": [
    "**Ans:** Validation set is a set used to compare between different training models.\n",
    "\n",
    "Let's say we have a linear model and we want to perform some hyperparameter tuning to reduce the generalization error. One way to do this 100 different models with 100 different hyperparameter values using the training set and finding the generalization error with the test set. You find the best hyperparameter value gives you 5% generalization error.\n",
    "\n",
    "So you launch the model into production and find you're seeing 15% generalization error. This isn't going as expected. What happened?\n",
    "\n",
    "The problem is that for each iteration of hyperparameter tuning, you measured the generalization error then updated the model using the same test set. In other words, your produced the best generalization error for the test set. The test set no longer represents cases the model hasn't seen before.\n",
    "\n",
    "A common solution to this problem is to have a second holdout set called the validation set. You train multiple models with various hyperparameters using the training set, you select the model and hyperparameters that perform best on the validation set, and when you are happy about your model you run a single final test against the test set to get an estimate of the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e433cc-cc7c-49dd-be7f-b92772401aa7",
   "metadata": {},
   "source": [
    "**18. What precisely is the train-dev kit, when will you need it, how do you put it to use?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852ee649-8945-4ab2-a881-8ed7b474275b",
   "metadata": {},
   "source": [
    "**Ans:** Cross-validation is a tool to compare models without needing a separate validation set. It is preferred over validation set because we can save from breaking of part of the training set to create a validation set, as having more data is valuable regardless.\n",
    "\n",
    "In the process of building models that learn from data, we need to find the best parameters of the model and best model out of all other available ones. If we don’t have dev data then we’ll train all the models and pick the model with the best performance on training data. By doing so, we are taking 2 decisions with a single process i.e.\n",
    "\n",
    "1. Parameter choice\n",
    "\n",
    "2. Model choice\n",
    "\n",
    "While having dev set split, first training algorithm makes the choice for optimal parameters and then those parameters are used on dev data to help us find best model architecture as compared to both choices made together by learning algorithm itself.\n",
    "\n",
    "Dev set helps us in reducing the complexity of diagnosis if things won’t go fine i.e. we’ll be able to assign error to either choice of parameters or picking up model architecture very concretely.\n",
    "\n",
    "Lack of dev set and using only the training set doesn’t give you clue about which choice went wrong and luck rather than skill will be helpful to debug your learning algorithm there and to make decision further to improve the model accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce93867-b441-4864-866a-8aa956549719",
   "metadata": {},
   "source": [
    "**19. What could go wrong if you use the test set to tune hyperparameters?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcef83e5-615d-4243-8a5e-9af336a97937",
   "metadata": {},
   "source": [
    "**Ans:** If you tune hyperparameters using the test sets, then it may not perform well on the out-of-sample data because the model is tuned just for that specific set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
